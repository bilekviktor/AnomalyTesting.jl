---
title: The Effect of the Loss Function on Quality of Anomaly Detection - Report 6.1.
author: Viktor BÃ­lek
date: 28.1.2021
---


# Introduction
Comparison of maximum-likelihood and calibrated loss function
for anomaly detection using SPTN model.

```julia; echo = false; results = "hidden"
using ToyProblems, DistributionsAD, SumProductTransform, Unitary, Flux, Setfield
using Distributions, Statistics, MLDataPattern, EvalMetrics
using Flux:throttle
using SumProductTransform: fit!, maptree
using ToyProblems: flower2
using SumProductTransform: ScaleShift, SVDDense
using DistributionsAD: TuringMvNormal
using DelimitedFiles
include("..//src//AnomalyTools.jl")

using Plots

function sptn(d, n, l)
	m = TransformationNode(ScaleShift(d),  TuringMvNormal(d,1f0))
	for i in 1:l
		m = SumNode([TransformationNode(SVDDense(d, identity, :butterfly), m)
					for i in 1:n])
	end
	return(m)
end
```
# Anomaly detection terms:
- fp - number of false positives etc.
- p - positives = tp + fn
- fpr - false positive rate = fp/p = fp/(tp + fn) = FALL OUT
- tpr - true positive rate = tp/p = 1 - fnr = SENSITIVITY, RECALL, HIT RATE
- tnr - true negative rate = tn/n = 1 - fpr = SPECIFITY, SELECTIVITY
- fnr - ....................................... = MISS RATE
- acc - ACCURACY = (tp + tn)/(p + n)

# Qunatile comparison with different percentage intervals on anomaly detection
Comparsion of mlm loss functions with different qunatile percentages.

# Interval [0.0; 1.0]

```julia;
m1 = sptn(2, 9, 2)
x_train = flower2(100000, npetals=9)
x_val = flower2(1000, npetals=9)
x = RandomBatches(x_train, 1000, 1000)

qx = (lkl_quantile(m1, batch, (0.0, 1.0)) for batch in x)

loss(x) = -mean(logpdf(m1, x))

ps = Flux.params(m1)

opt = ADAM(0.01)
Flux.Optimise.train!(x -> loss(getobs(x)), ps, qx, opt)

qval = lkl_quantile(m1, x_val, (0.0,1.0))
println("[0.0; 1.0] Q loss: ", loss(qval))
```
Heatmap:
```julia; echo = false
xx = reduce(hcat,[[v[1],v[2]] for v in Iterators.product(-10.0:0.1:10, -10.0:0.1:10)])
res = reshape(logpdf(m1, xx), 201, 201)
Plots.heatmap(exp.(res))
```
Generating anomalies and test set. FPR at 0.05
```julia; results="hidden"
x_test = flower2(100000, npetals=9)
x_anom = 10 .* (rand(2, 5000) .- 0.5)
fpr = 0.05
```
Evaluation
```julia;
targets1, scores1 = target_score(x_test, x_anom, m1, fpr)
binary_eval_report(targets1, scores1)
```
ROC plot
```julia; echo = false
roc_comparison(targets1, scores1, fpr)
```


# Interval [0.0; 0.05]

```julia;
m2 = sptn(2, 9, 2)
x_train = flower2(100000, npetals=9)
x_val = flower2(1000, npetals=9)
x = RandomBatches(x_train, 1000, 10000)

qx = (lkl_quantile(m2, batch, (0.0, 0.05)) for batch in x)

loss(x) = -mean(logpdf(m2, x))

ps = Flux.params(m2)

opt = ADAM(0.01)
Flux.Optimise.train!(x -> loss(getobs(x)), ps, qx, opt)

qval = lkl_quantile(m2, x_val, (0.0, 0.05))
println("[0.0; 0.05] Q loss: ", loss(qval))
```
Heatmap:
```julia; echo = false
xx = reduce(hcat,[[v[1],v[2]] for v in Iterators.product(-10.0:0.1:10, -10.0:0.1:10)])
res = reshape(logpdf(m2, xx), 201, 201)
Plots.heatmap(exp.(res))
```
Generating anomalies and test set. FPR at 0.05
```julia; results="hidden"
x_test = flower2(100000, npetals=9)
x_anom = 10 .* (rand(2, 5000) .- 0.5)
fpr = 0.05
```
Evaluation
```julia;
targets2, scores2 = target_score(x_test, x_anom, m2, fpr)
binary_eval_report(targets2, scores2)
```
ROC plot
```julia; echo = false
roc_comparison(targets2, scores2, fpr)
```



# Interval [0.025; 0.075]

```julia;
m3 = sptn(2, 9, 2)
x_train = flower2(100000, npetals=9)
x_val = flower2(1000, npetals=9)
x = RandomBatches(x_train, 1000, 10000)

qx = (lkl_quantile(m3, batch, (0.025, 0.075)) for batch in x)

loss(x) = -mean(logpdf(m3, x))

ps = Flux.params(m3)

opt = ADAM(0.01)
Flux.Optimise.train!(x -> loss(getobs(x)), ps, qx, opt)

qval = lkl_quantile(m3, x_val, (0.025, 0.075))
println("[0.025; 0.075] Q loss: ", loss(qval))
```
Heatmap:
```julia; echo = false
xx = reduce(hcat,[[v[1],v[2]] for v in Iterators.product(-10.0:0.1:10, -10.0:0.1:10)])
res = reshape(logpdf(m3, xx), 201, 201)
Plots.heatmap(exp.(res))
```

Generating anomalies and test set. FPR at 0.05
```julia; results="hidden"
x_test = flower2(100000, npetals=9)
x_anom = 10 .* (rand(2, 5000) .- 0.5)
fpr = 0.05
```
Evaluation
```julia;
targets3, scores3 = target_score(x_test, x_anom, m3, fpr)
binary_eval_report(targets3, scores3)
```
ROC plot
```julia; echo = false
roc_comparison(targets3, scores3, fpr)
```

# Interval [0.05; 1.0]

```julia;
m4 = sptn(2, 9, 2)
x_train = flower2(100000, npetals=9)
x_val = flower2(1000, npetals=9)
x = RandomBatches(x_train, 1000, 1500)

qx = (lkl_quantile(m4, batch, (0.05, 1.0)) for batch in x)

loss(x) = -mean(logpdf(m4, x))

ps = Flux.params(m4)

opt = ADAM(0.01)
Flux.Optimise.train!(x -> loss(getobs(x)), ps, qx, opt)

qval = lkl_quantile(m4, x_val, (0.05, 1.0))
println("[0.05; 1.0] Q loss: ", loss(qval))
```
Heatmap:
```julia; echo = false
xx = reduce(hcat,[[v[1],v[2]] for v in Iterators.product(-10.0:0.1:10, -10.0:0.1:10)])
res = reshape(logpdf(m4, xx), 201, 201)
Plots.heatmap(exp.(res))
```

Generating anomalies and test set. FPR at 0.05
```julia; results="hidden"
x_test = flower2(100000, npetals=9)
x_anom = 10 .* (rand(2, 5000) .- 0.5)
fpr = 0.05
```
Evaluation
```julia;
targets4, scores4 = target_score(x_test, x_anom, m4, fpr)
binary_eval_report(targets4, scores4)
```
ROC plot
```julia; echo = false
roc_comparison(targets4, scores4, fpr)
```


# Comparison of all three versions
Q loss inerval: [0.0; 1.0]
```julia;
binary_eval_report(targets1, scores1)
```
Q loss inerval: [0.0; 0.05]
```julia;
binary_eval_report(targets2, scores2)
```
Q loss inerval: [0.025; 0.075]
```julia;
binary_eval_report(targets3, scores3)
```
Q loss inerval: [0.05; 1.0]
```julia;
binary_eval_report(targets4, scores4)
```
ROC plot comparison
```julia; echo = false
fpr = 0.05
tresh_line = [fpr 0.0; fpr 1.0]
rocplot([targets1, targets2, targets3, targets4],
        [scores1, scores2, scores3, scores4],
        label = ["[0.0; 1.0]" "[0.0; 0.05]" "[0.025; 0.075]" "[0.05; 1.0]"])
plot!(tresh_line[:, 1], tresh_line[:, 2], linestyle =:dashdot, linecolor=:grey, label="fpr treshhold")
```
